\chapter{Introduction}

\section{Research background}

The history of remote sensing intersects closely with the launch of satellites like Landsat, which revolutionized Earth observation from space. Initially, the remote sensing community predominantly relied on low and medium resolution images from these satellites for various image analyses and earth observation applications.

However, with the advancement in satellite sensors, access to high-resolution images has become more prevalent. These high-resolution images offer finer details and greater clarity, thereby enhancing the capabilities of earth observation and computer vision applications, such as semantic segmentation. However, with abundance of details is the challenge of high texture complexity which can pose obstacles to feature extraction due to several factors. Firstly, the increased level of detail results in higher dimensionality which would increase the need for more computing resources. This was however addressed by progress in hardware, notably the Graphical Processing Unit(GPU). Secondly, the abundance of texture can introduce artifacts and noise into the data, which may obscure underlying patterns. Moreover, the spectral variability across different spatial scales adds another layer of complexity. Objects may appear significantly different in size and shape depending on the resolution of the image, creating hierarchical structures that further complicate the definition of semantic rules for semantic segmentation and object recognition tasks. Besides all these, there is the challenge of spectral similarity, which can create a semantic gap in image analysis. Some objects may have similar spectral values, for example buildings and other impervious surfaces such as pavements in urban areas where they dominate the landscape making it difficult to distinguish them only by their spectral signature.\cite{hossain_segmentation_2019}

Consequently, traditional pixel-based techniques have become inadequate for the analysis of such imagery, leading to the adoption of Object-Based Image Analysis (OBIA). This represents a paradigm shift that addresses complex classes, which cannot be distinguished by spectral characteristics alone. These classes are defined by their spatial, textural, and geometrical relationships \cite{blaschke_object_2010}.

In contrast to traditional pixel-centric methods, Object-Based Image Analysis (OBIA) adopts a two-step approach to image analysis. Firstly, it identifies objectsâ€”compact, non-overlapping entities with semantic meaning. Subsequently, it extracts representative characteristics or features from these objects to aid in classification. This methodology leverages additional characteristics beyond spectral values, including shape, size, color, homogeneity, and compactness, among others. It also aligns with the concept of hierarchical organization of information, acknowledging the existence of different levels of detail at various scales \cite{lang_hierarchical_2003}.

The approach offers flexibility by allowing the use of manually crafted features, such as NDVI, or deep features, which are extracted in an end-to-end manner. The success of downstream applications relies heavily on both the initial segmentation and definition of objects as well as the subsequent feature extraction process. Various end-to-end feature extraction techniques, such as those utilizing convolutional neural networks \cite{audebert_how_2016}, pixel-set encoders \cite{garnot_satellite_2020}, and deformable convolutions \cite{zhao_superpixel_2022}, have made substantial progress. Nevertheless, these methods have fallen short in automatically extracting crucial geometric information necessary for accurate feature identification.

Therefore, this study undertakes a thorough comparison of diverse segmentation algorithms to illuminate the challenges associated with creating image objects. While the objective is to highlight the limitations of existing feature encoders on objects by comparing them in an OBIA pipeline it is essential to understand how these algorithms work. Additionally, we plan to propose a novel approach that leverages Graph Neural Networks, to facilitate the automatic extraction of the spectral and textural features and especially the geometric features from arbitrarily shaped objects.



%\bibliography{Thesisref}